{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b3c203ae-1b03-4751-9e5d-cbdd9a01c003",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.nasdaq.com/market-activity/stocks/screener\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('tickers.csv')\n",
    "\n",
    "# Extract the 'Symbol' column into a list\n",
    "ticker_symbols = df['Symbol'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1065aea-1e4d-4963-8a7f-a1322683b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Directory to save the data\n",
    "data_dir = \"ticker_data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Function to fetch and save data for a list of tickers\n",
    "def fetch_and_save_data(tickers):\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=365*10)\n",
    "    \n",
    "    try:\n",
    "        #print(f\"Fetching data for tickers: {tickers}\")\n",
    "        data = yf.download(tickers, start=start_date, end=end_date, group_by='ticker')\n",
    "        \n",
    "        for ticker in tickers:\n",
    "            ticker_data = data[ticker]\n",
    "            if not ticker_data.empty:\n",
    "                file_path = os.path.join(data_dir, f\"{ticker}.csv\")\n",
    "                ticker_data.to_csv(file_path)\n",
    "                print(f\"Data for {ticker} saved successfully.\")\n",
    "            else:\n",
    "                print(f\"No data found for {ticker}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for tickers: {e}\")\n",
    "\n",
    "# Function to split the list into chunks of specified size\n",
    "def chunk_list(lst, chunk_size):\n",
    "    for i in range(0, len(lst), chunk_size):\n",
    "        yield lst[i:i + chunk_size]\n",
    "\n",
    "# Process tickers in chunks of 500\n",
    "chunk_size = 500\n",
    "for ticker_chunk in chunk_list(ticker_symbols, chunk_size):\n",
    "    fetch_and_save_data(ticker_chunk)\n",
    "\n",
    "print(\"Data fetching completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "318386e5-c7d4-47a1-84d3-a7aec994a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_and_resample_ticker_data():\n",
    "    ticker_data_dir = 'ticker_data'\n",
    "    weekly_data_dir = 'weekly_data'\n",
    "    \n",
    "    if not os.path.exists(weekly_data_dir):\n",
    "        os.makedirs(weekly_data_dir)\n",
    "    \n",
    "    # List all CSV files in the ticker_data directory\n",
    "    ticker_files = [f for f in os.listdir(ticker_data_dir) if f.endswith('.csv')]\n",
    "    \n",
    "    # Dictionary to store dataframes for each ticker\n",
    "    ticker_dataframes = {}\n",
    "    \n",
    "    for file in ticker_files:\n",
    "        # Extract the ticker symbol from the file name (assuming it's the file name without extension)\n",
    "        ticker_symbol = os.path.splitext(file)[0]\n",
    "        \n",
    "        # Load the CSV file into a DataFrame\n",
    "        df = pd.read_csv(os.path.join(ticker_data_dir, file))\n",
    "        \n",
    "        # Ensure the date column is in datetime format\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        \n",
    "        # Set the date column as the index\n",
    "        df.set_index('date', inplace=True)\n",
    "        \n",
    "        # Store the DataFrame in the dictionary\n",
    "        ticker_dataframes[ticker_symbol] = df\n",
    "\n",
    "    # Concatenate all dataframes along the columns axis, aligning on the date index\n",
    "    combined_df = pd.concat(ticker_dataframes.values(), axis=1, keys=ticker_dataframes.keys())\n",
    "    \n",
    "    # Select only numeric columns for resampling\n",
    "    numeric_combined_df = combined_df.select_dtypes(include='number')\n",
    "    \n",
    "    # Resample the combined dataframe to weekly frequency, using the mean for example\n",
    "    weekly_combined_df = numeric_combined_df.resample('W').mean()\n",
    "    \n",
    "    # Iterate over each ticker to save the resampled data back to individual files\n",
    "    for ticker_symbol in ticker_dataframes.keys():\n",
    "        # Extract the ticker's resampled data\n",
    "        ticker_weekly_df = weekly_combined_df[ticker_symbol]\n",
    "        \n",
    "        # Reset the index to have the date as a column again\n",
    "        ticker_weekly_df.reset_index(inplace=True)\n",
    "        \n",
    "        # Write the weekly data to a new CSV file in the weekly_data directory\n",
    "        ticker_weekly_df.to_csv(os.path.join(weekly_data_dir, f'{ticker_symbol}_weekly.csv'), index=False)\n",
    "\n",
    "# Call the function to execute the task\n",
    "load_and_resample_ticker_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bf9b1c5b-47bf-4b68-a971-d2022e4be3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def calculate_rsi(df, column='Close', period=14):\n",
    "    delta = df[column].diff()\n",
    "    gain = delta.clip(lower=0).rolling(window=period, min_periods=1).mean()\n",
    "    loss = -delta.clip(upper=0).rolling(window=period, min_periods=1).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi\n",
    "\n",
    "def calculate_mfi(df, period=14):\n",
    "    typical_price = (df['High'] + df['Low'] + df['Close']) / 3\n",
    "    money_fLow = typical_price * df['Volume']\n",
    "    positive_fLow = money_fLow.where(typical_price > typical_price.shift(1), 0).rolling(window=period, min_periods=1).sum()\n",
    "    negative_fLow = money_fLow.where(typical_price < typical_price.shift(1), 0).rolling(window=period, min_periods=1).sum()\n",
    "    mfi = 100 - (100 / (1 + positive_fLow / negative_fLow))\n",
    "    return mfi\n",
    "\n",
    "def calculate_ultimate_oscillator(df, short_period=7, mid_period=14, long_period=28):\n",
    "    # Ensure the DataFrame is sorted by date\n",
    "    df = df.sort_index()\n",
    "\n",
    "    # Calculate Buying Pressure (BP) and True Range (TR)\n",
    "    df['Prior Close'] = df['Close'].shift(1)\n",
    "    df['BP'] = df['Close'] - df[['Low', 'Prior Close']].min(axis=1)\n",
    "    df['TR'] = df[['High', 'Prior Close']].max(axis=1) - df[['Low', 'Prior Close']].min(axis=1)\n",
    "    \n",
    "    # Calculate average BP and TR for each period\n",
    "    df['Avg7_BP'] = df['BP'].rolling(window=short_period).sum()\n",
    "    df['Avg7_TR'] = df['TR'].rolling(window=short_period).sum()\n",
    "    df['Avg14_BP'] = df['BP'].rolling(window=mid_period).sum()\n",
    "    df['Avg14_TR'] = df['TR'].rolling(window=mid_period).sum()\n",
    "    df['Avg28_BP'] = df['BP'].rolling(window=long_period).sum()\n",
    "    df['Avg28_TR'] = df['TR'].rolling(window=long_period).sum()\n",
    "    \n",
    "    # Calculate raw UO components\n",
    "    df['R1'] = df['Avg7_BP'] / df['Avg7_TR']\n",
    "    df['R2'] = df['Avg14_BP'] / df['Avg14_TR']\n",
    "    df['R3'] = df['Avg28_BP'] / df['Avg28_TR']\n",
    "    \n",
    "    # Calculate Ultimate Oscillator\n",
    "    df['Ultimate Oscillator'] = 100 * (4 * df['R1'] + 2 * df['R2'] + df['R3']) / (4 + 2 + 1)\n",
    "    \n",
    "    return df['Ultimate Oscillator']\n",
    "\n",
    "def calculate_obv(df):\n",
    "    # Calculate daily returns\n",
    "    df['Daily Return'] = df['Close'].diff()\n",
    "    \n",
    "    # Calculate the direction of the volume flow\n",
    "    df['Direction'] = 0\n",
    "    df.loc[df['Daily Return'] > 0, 'Direction'] = 1\n",
    "    df.loc[df['Daily Return'] < 0, 'Direction'] = -1\n",
    "    \n",
    "    # Calculate OBV\n",
    "    df['OBV'] = (df['Volume'] * df['Direction']).cumsum()\n",
    "    \n",
    "    \n",
    "    return df['OBV']\n",
    "    \n",
    "def calculate_close_open_avg_volume(df):\n",
    "    # Calculate the average of 'Close' and 'Open' prices\n",
    "    df['Close_Open_Avg'] = (df['Close'] + df['Open']) / 2\n",
    "    \n",
    "    # Multiply the average with 'Volume'\n",
    "    df['Close_Open_Avg_Volume'] = df['Close_Open_Avg'] * df['Volume']\n",
    "    \n",
    "    return df['Close_Open_Avg_Volume']\n",
    "    \n",
    "def add_technical_indicators():\n",
    "    weekly_data_dir = 'weekly_data'\n",
    "    ta_data_dir = 'ta_data'\n",
    "    \n",
    "    if not os.path.exists(ta_data_dir):\n",
    "        os.makedirs(ta_data_dir)\n",
    "    \n",
    "    # List all CSV files in the weekly_data directory\n",
    "    ticker_files = [f for f in os.listdir(weekly_data_dir) if f.endswith('.csv')]\n",
    "    \n",
    "    for file in ticker_files:\n",
    "        # Load the CSV file into a DataFrame\n",
    "        df = pd.read_csv(os.path.join(weekly_data_dir, file))\n",
    "        \n",
    "        if df.empty:\n",
    "            continue\n",
    "        \n",
    "        # Ensure the date column is in datetime format\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        \n",
    "        # Sort the dataframe by date\n",
    "        df.sort_values(by='date', inplace=True)\n",
    "        \n",
    "        # Calculate technical indicators\n",
    "        df['RSI'] = calculate_rsi(df)\n",
    "        df['MFI'] = calculate_mfi(df)\n",
    "        df['ULTOSC'] = calculate_ultimate_oscillator(df)\n",
    "        df['OBV'] = calculate_obv(df)\n",
    "        df['MON'] = calculate_close_open_avg_volume(df)\n",
    "        \n",
    "        # Remove any rows with NaN values introduced by the indicators\n",
    "        df.dropna(inplace=True)\n",
    "        \n",
    "        # Save the updated DataFrame to the ta_data directory\n",
    "        df.to_csv(os.path.join(ta_data_dir, file), index=False)\n",
    "\n",
    "# Call the function to execute the task\n",
    "add_technical_indicators()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "19ca9f54-8047-4ef2-8f32-9aa8033b5492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Open     High        Low      Close  Adj Close      Volume  \\\n",
      "date                                                                          \n",
      "2016-03-27   5.280000   5.4150   4.990000   5.107500   0.062033    312025.0   \n",
      "2018-08-19   6.416000   6.6640   6.356000   6.570000   0.210416    216060.0   \n",
      "2018-09-02   1.980000   2.7500   1.768000   2.262000   2.262000   5711040.0   \n",
      "2019-04-14   2.116000   2.8860   1.948000   2.508000   2.508000  22679300.0   \n",
      "2019-04-21   2.760000   3.0400   2.632500   2.852500   2.852500   2961850.0   \n",
      "...               ...      ...        ...        ...        ...         ...   \n",
      "2024-05-12  42.128001  42.9470  41.620799  42.382001  42.382001   4026700.0   \n",
      "2024-05-19  44.384000  45.0490  43.564000  44.304000  44.304000   3761720.0   \n",
      "2024-05-26  42.140000  42.3770  41.230000  41.314000  41.314000   2514900.0   \n",
      "2024-06-02  39.572499  40.3325  39.316250  39.797500  39.797500   3223475.0   \n",
      "2024-06-09  41.806000  42.6716  41.508000  42.346000  42.346000   3205060.0   \n",
      "\n",
      "                  RSI        MFI     ULTOSC  Daily Return  Direction  \\\n",
      "date                                                                   \n",
      "2016-03-27  35.540697  81.057619  40.543912      0.013500          1   \n",
      "2018-08-19  66.793699  94.938644  62.909589      1.282000          1   \n",
      "2018-09-02  32.084451  13.610435  37.309033     -4.228000         -1   \n",
      "2019-04-14  90.553411  99.447245  69.078790      1.510000          1   \n",
      "2019-04-21  91.694954  99.518032  68.761735      0.344500          1   \n",
      "...               ...        ...        ...           ...        ...   \n",
      "2024-05-12  17.588100  28.634224  31.763922      0.654001          1   \n",
      "2024-05-19  25.162183  34.275006  37.247462      1.921999          1   \n",
      "2024-05-26  22.643439  37.581561  33.742583     -2.990000         -1   \n",
      "2024-06-02  23.517031  38.348862  32.972495     -1.516500         -1   \n",
      "2024-06-09  25.420824  37.122140  43.075803      2.548500          1   \n",
      "\n",
      "                   OBV  Close_Open_Avg  Close_Open_Avg_Volume           MON  \\\n",
      "date                                                                          \n",
      "2016-03-27    640055.0        5.193750           1.620580e+06  1.620580e+06   \n",
      "2018-08-19   1239140.0        6.493000           1.402878e+06  1.402878e+06   \n",
      "2018-09-02  -4618480.0        2.121000           1.211312e+07  1.211312e+07   \n",
      "2019-04-14  17873825.0        2.312000           5.243454e+07  5.243454e+07   \n",
      "2019-04-21  20835675.0        2.806250           8.311692e+06  8.311692e+06   \n",
      "...                ...             ...                    ...           ...   \n",
      "2024-05-12  81860420.0       42.255001           1.701482e+08  1.701482e+08   \n",
      "2024-05-19  85622140.0       44.344000           1.668097e+08  1.668097e+08   \n",
      "2024-05-26  83107240.0       41.727000           1.049392e+08  1.049392e+08   \n",
      "2024-06-02  79883765.0       39.684999           1.279236e+08  1.279236e+08   \n",
      "2024-06-09  83088825.0       42.076000           1.348561e+08  1.348561e+08   \n",
      "\n",
      "           ticker  \n",
      "date               \n",
      "2016-03-27   AACG  \n",
      "2018-08-19   AACG  \n",
      "2018-09-02   AACG  \n",
      "2019-04-14   AACG  \n",
      "2019-04-21   AACG  \n",
      "...           ...  \n",
      "2024-05-12      Z  \n",
      "2024-05-19      Z  \n",
      "2024-05-26      Z  \n",
      "2024-06-02      Z  \n",
      "2024-06-09      Z  \n",
      "\n",
      "[984471 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_ta_data():\n",
    "    ta_data_dir = 'ta_data'\n",
    "    \n",
    "    # List all CSV files in the ta_data directory\n",
    "    ticker_files = [f for f in os.listdir(ta_data_dir) if f.endswith('.csv')]\n",
    "    \n",
    "    # List to store DataFrames\n",
    "    dataframes = []\n",
    "    \n",
    "    for file in ticker_files:\n",
    "        # Extract the ticker symbol from the file name (assuming it's the file name without extension)\n",
    "        ticker_symbol = os.path.splitext(file)[0].split('_')[0]\n",
    "        # Load the CSV file into a DataFrame\n",
    "        df = pd.read_csv(os.path.join(ta_data_dir, file))\n",
    "        \n",
    "        if df.empty:\n",
    "            continue\n",
    "        \n",
    "        # Add a column for the ticker symbol\n",
    "        df['ticker'] = ticker_symbol\n",
    "        \n",
    "        # Remove rows where 'MON' column is less than 1 million\n",
    "        df = df[df['MON'] >= 1_000_000]   \n",
    "        \n",
    "        # Append the DataFrame to the list\n",
    "        dataframes.append(df)\n",
    "    \n",
    "    # Concatenate all DataFrames\n",
    "    combined_df = pd.concat(dataframes)\n",
    "    \n",
    "    # Ensure the date column is in datetime format\n",
    "    combined_df['date'] = pd.to_datetime(combined_df['date'])\n",
    "    \n",
    "    # Set the date column as the index\n",
    "    combined_df.set_index('date', inplace=True)\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "\n",
    "# Load the data\n",
    "combined_df = load_ta_data()\n",
    "print(combined_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ee00eac5-8d28-460a-9edf-ab432e44929c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             date ticker  pct_change\n",
      "1549   2014-12-28   AAPL    2.829707\n",
      "2974   2014-12-28    XOM    4.810120\n",
      "2978   2014-12-28  GOOGL    5.157897\n",
      "2993   2015-01-04   AAPL   -1.182778\n",
      "4233   2015-01-04   GILD    3.897343\n",
      "...           ...    ...         ...\n",
      "982025 2024-06-09   NVDA    6.182654\n",
      "982026 2024-06-09   TSLA   -0.651724\n",
      "982027 2024-06-09   AAPL    2.183237\n",
      "982032 2024-06-09    GME   -4.619582\n",
      "982029 2024-06-09  GOOGL   -0.696839\n",
      "\n",
      "[2395 rows x 3 columns]\n",
      "          date  pct_change\n",
      "0   2014-12-28    4.265908\n",
      "1   2015-01-04    1.248673\n",
      "2   2015-01-11   -2.105625\n",
      "3   2015-01-18   -2.170253\n",
      "4   2015-01-25    1.869895\n",
      "..         ...         ...\n",
      "489 2024-05-12    1.756213\n",
      "490 2024-05-19   -7.442087\n",
      "491 2024-05-26    3.018893\n",
      "492 2024-06-02    2.726708\n",
      "493 2024-06-09    0.479549\n",
      "\n",
      "[494 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming combined_df is already defined and contains the necessary data\n",
    "# combined_df = ...\n",
    "\n",
    "# Step 0: Reset index to make 'date' a column\n",
    "combined_df = combined_df.reset_index()\n",
    "\n",
    "# Step 1: Sort the DataFrame based on the 'RSI' column for each date in descending order\n",
    "combined_df = combined_df.sort_values(by=['date', 'MON'], ascending=[True, False])\n",
    "\n",
    "# Step 2: Select the top n tickers with the highest RSI score for each date\n",
    "n = 5  # For example, we can set n to 5\n",
    "top_n_df = combined_df.groupby('date').head(n).copy()\n",
    "\n",
    "# Step 3: Calculate the percentage change in the 'Close' column for the selected tickers between the current week and the next week\n",
    "# Create a new column for the percentage change\n",
    "top_n_df.loc[:, 'pct_change'] = top_n_df.groupby('ticker')['Close'].pct_change(periods=1) * 100\n",
    "\n",
    "# Step 4: Summarize the results\n",
    "summary = top_n_df.dropna(subset=['pct_change'])[['date', 'ticker', 'pct_change']]\n",
    "print(summary)\n",
    "\n",
    "# Additionally, you can group by date to see the average percentage change for each date\n",
    "date_summary = summary.groupby('date')['pct_change'].mean().reset_index()\n",
    "print(date_summary)\n",
    "\n",
    "# Step 5: Save the summary to a CSV file\n",
    "date_summary.to_csv('summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f3a62e-4d92-4b27-b46c-904dc181b839",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
